{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6772,"status":"ok","timestamp":1655624003937,"user":{"displayName":"沈妙","userId":"00881081642719026804"},"user_tz":-480},"id":"2ZovPqvD9Mz8","outputId":"8a87dad0-d274-47d1-b912-8318d1028310"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rasterio\n","  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n","\u001b[K     |████████████████████████████████| 19.3 MB 1.4 MB/s \n","\u001b[?25hCollecting affine\n","  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n","Collecting click-plugins\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2022.6.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n","Collecting snuggs>=1.4.1\n","  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n","Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n","Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"]}],"source":["#/usr/local/lib/python3.7/dist-packages/torch/nn/modules/unsampling.py\n","# def forward(self, input: Tensor) -> Tensor:\n","#         return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)\n","# !pip install rasterio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57482,"status":"ok","timestamp":1655624061415,"user":{"displayName":"沈妙","userId":"00881081642719026804"},"user_tz":-480},"id":"SNQ2zeEd9YVr","outputId":"451210b7-7f36-4db3-b990-0e821549f210"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","[Errno 2] No such file or directory: '/MyDrive/file'\n","/content\n"]}],"source":["# from google.colab import drive\n","# #drive.mount('/content/drive',force_remount=True)\n","# drive.mount('/content/drive')\n","# %cd /MyDrive/file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eN8IAjse9afU"},"outputs":[],"source":["nor=[\n","    [1612.2641794179053,694.6404158569574],\n","    [1379.8899556061613,734.589213934987],\n","    [1344.4295633683826,731.6118897277566],\n","    [1195.157229000143,860.603745394514],\n","    [1439.168369746529,771.3569863637912],\n","    [2344.2498120705645,921.6300590130161],\n","    [2796.473722876989,1088.0256714514674],\n","    [2578.4108992777597,1029.246558060433],\n","    [3023.817505678254,1205.1064480965915],\n","    [476.7287418382585,331.6878880293502],\n","    [59.24111403905757,130.40242222578226],\n","    [1989.1945548720423,993.7071664926801],\n","    [1152.4886461779677, 768.8907975412457],\n","    [-0.2938129263276281,0.21578320121968173],\n","    [-0.36928344017880277,0.19538602918264955],\n","    [-6393.00646782349,0.19538602918264955],\n","    [-2398.566478742078,0.19538602918264955]\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FP0K8zzk9bZr"},"outputs":[],"source":["from osgeo import gdal\n","import torch\n","from torchvision import transforms\n","import torchvision.transforms.functional as F\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","import numpy as np\n","import random\n","from PIL import Image\n","from time import time\n","import csv\n","import os\n","import numpy as np\n","import rasterio\n","import argparse\n","\n","from tqdm.notebook import tqdm\n","from IPython.display import clear_output\n","\n","import os\n","from IPython.display import display\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBwn07XN9eI7"},"outputs":[],"source":["LR = 5e-4\n","EPOCHS = 1\n","EPOCHS_PER_UPDATE = 1\n","\n","CHANNEL=5\n","outputnumber=3\n","\n","path='./dataset/v1.1/data/flood_events/HandLabeled/'  #修改\n","model_save_path='./checkpoints/'  #修改\n","# train\n","S2_path = path+'S2Hand'\n","Labels_path = path+'LabelHand'\n","# test\n","test_path = './dataset/test/post/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xS3AwVoJCHwI"},"outputs":[],"source":["class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, middle_channels, out_channels):\n","        super().__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(middle_channels)\n","        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        return out\n","\n","class NestedUNet(nn.Module):\n","    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n","        super().__init__()\n","\n","        nb_filter = [32, 64, 128, 256, 512,1024]\n","\n","        self.deep_supervision = deep_supervision\n","\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n","        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n","        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n","        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n","        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n","        \n","\n","        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n","        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n","        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n","        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n","        \n","\n","        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n","        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n","        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n","        \n","\n","        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n","        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n","        \n","\n","        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n","        \n","\n","       \n","\n","\n","\n","        if self.deep_supervision:\n","            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            \n","        else:\n","            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","\n","\n","    def forward(self, input):\n","        x0_0 = self.conv0_0(input)\n","        x1_0 = self.conv1_0(self.pool(x0_0))\n","        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n","\n","        x2_0 = self.conv2_0(self.pool(x1_0))\n","        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n","        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n","\n","        x3_0 = self.conv3_0(self.pool(x2_0))\n","        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n","        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n","        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n","\n","        x4_0 = self.conv4_0(self.pool(x3_0))\n","        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n","        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n","        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n","        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n","\n","        \n","\n","        if self.deep_supervision:\n","            output1 = self.final1(x0_1)\n","            output2 = self.final2(x0_2)\n","            output3 = self.final3(x0_3)\n","            output4 = self.final4(x0_4)\n","            \n","            if outputnumber==0:\n","              return output1\n","            elif outputnumber==1:\n","              return output2\n","            elif outputnumber==2:\n","              return output3\n","            elif outputnumber==3:\n","              return output4\n","            \n","\n","         \n","        else:\n","            output = self.final(x0_4)\n","            return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ekLRpZ-R9gM8"},"outputs":[],"source":["def processTestIm(data):\n","  (sen2, y) = data\n","  s2, label = sen2.copy(), y.copy()\n","\n","  norm = transforms.Normalize([nor[6][0],\n","         nor[7][0],\n","         nor[8][0],\n","         nor[11][0],\n","         nor[12][0]],[nor[6][1],\n","         nor[7][1],\n","         nor[8][1],\n","         nor[11][1],\n","         nor[12][1]])\n","\n","\n","  # convert to PIL for easier transforms\n","  \n","\n","  band1 = Image.fromarray(s2[0]).resize((512,512))\n","\n","  band2 = Image.fromarray(s2[1]).resize((512,512))\n","  # print(band2.mean())\n","  band3 = Image.fromarray(s2[2]).resize((512,512))\n","  band4 = Image.fromarray(s2[3]).resize((512,512))\n","  band5 = Image.fromarray(s2[4]).resize((512,512))\n","  band6 = Image.fromarray(s2[5]).resize((512,512))\n","  band7 = Image.fromarray(s2[6]).resize((512,512))\n","  band8 = Image.fromarray(s2[7]).resize((512,512))\n","  # print(band8.mean())\n","  band8A = Image.fromarray(s2[8]).resize((512,512))\n","  band9 = Image.fromarray(s2[9]).resize((512,512))\n","  # print(band10.mean())\n","  band10 = Image.fromarray(s2[10]).resize((512,512))\n","  band11 = Image.fromarray(s2[11]).resize((512,512))\n","  # print(band12.mean())\n","  band12 = Image.fromarray(s2[12]).resize((512,512))\n","\n","  \n","  label = Image.fromarray(label.squeeze()).resize((512,512))\n","\n","\n"," \n","\n","\n","  band1s = [F.crop(band1, 0, 0, 256, 256), F.crop(band1, 0, 256, 256, 256),\n","              F.crop(band1, 256, 0, 256, 256), F.crop(band1, 256, 256, 256, 256)]\n","  band2s = [F.crop(band2, 0, 0, 256, 256), F.crop(band2, 0, 256, 256, 256),\n","              F.crop(band2, 256, 0, 256, 256), F.crop(band2, 256, 256, 256, 256)]\n","  band3s = [F.crop(band3, 0, 0, 256, 256), F.crop(band3, 0, 256, 256, 256),\n","              F.crop(band3, 256, 0, 256, 256), F.crop(band3, 256, 256, 256, 256)]\n","  band4s = [F.crop(band4, 0, 0, 256, 256), F.crop(band4, 0, 256, 256, 256),\n","              F.crop(band4, 256, 0, 256, 256), F.crop(band4, 256, 256, 256, 256)]\n","  band5s = [F.crop(band5, 0, 0, 256, 256), F.crop(band5, 0, 256, 256, 256),\n","              F.crop(band5, 256, 0, 256, 256), F.crop(band5, 256, 256, 256, 256)]\n","  band6s = [F.crop(band6, 0, 0, 256, 256), F.crop(band6, 0, 256, 256, 256),\n","              F.crop(band6, 256, 0, 256, 256), F.crop(band6, 256, 256, 256, 256)]\n","  band7s = [F.crop(band7, 0, 0, 256, 256), F.crop(band7, 0, 256, 256, 256),\n","              F.crop(band7, 256, 0, 256, 256), F.crop(band7, 256, 256, 256, 256)]\n","  band8s = [F.crop(band8, 0, 0, 256, 256), F.crop(band8, 0, 256, 256, 256),\n","              F.crop(band8, 256, 0, 256, 256), F.crop(band8, 256, 256, 256, 256)]\n","  band9s = [F.crop(band9, 0, 0, 256, 256), F.crop(band9, 0, 256, 256, 256),\n","              F.crop(band9, 256, 0, 256, 256), F.crop(band9, 256, 256, 256, 256)]\n","  band10s = [F.crop(band10, 0, 0, 256, 256), F.crop(band10, 0, 256, 256, 256),\n","              F.crop(band10, 256, 0, 256, 256), F.crop(band10, 256, 256, 256, 256)]\n","  band11s = [F.crop(band11, 0, 0, 256, 256), F.crop(band11, 0, 256, 256, 256),\n","              F.crop(band11, 256, 0, 256, 256), F.crop(band11, 256, 256, 256, 256)]\n","  band12s = [F.crop(band12, 0, 0, 256, 256), F.crop(band12, 0, 256, 256, 256),\n","              F.crop(band12, 256, 0, 256, 256), F.crop(band12, 256, 256, 256, 256)]\n","  band8As = [F.crop(band8A, 0, 0, 256, 256), F.crop(band8A, 0, 256, 256, 256),\n","              F.crop(band8A, 256, 0, 256, 256), F.crop(band8A, 256, 256, 256, 256)]\n"," \n","  labels = [F.crop(label, 0, 0, 256, 256), F.crop(label, 0, 256, 256, 256),\n","            F.crop(label, 256, 0, 256, 256), F.crop(label, 256, 256, 256, 256)]\n","\n","\n","\n","  \n","  ims = [torch.stack((transforms.ToTensor()(x1).squeeze().float(),\n","                    transforms.ToTensor()(x2).squeeze().float(),\n","                    transforms.ToTensor()(x3).squeeze().float(),\n","                    transforms.ToTensor()(x4).squeeze().float(),\n","                    transforms.ToTensor()(x5).squeeze().float()))\n","                    for (x1,x2,x3,x4,x5,) in zip(band7s,band8s,band8As,band11s,band12s)]\n","\n","  \n","  \n","  ims = [norm(im) for im in ims]\n","  ims = torch.stack(ims)\n","  \n","  labels = [(transforms.ToTensor()(label).squeeze()) for label in labels]\n","  labels = torch.stack(labels)\n","  # print(labels)\n","  \n","  if torch.sum(labels.gt(.003) * labels.lt(.004)):\n","    labels *= 255\n","  labels=labels/1.0\n","  labels = labels.round()\n","  \n","  return ims, labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,8]).float().cuda(), ignore_index=255) \n","\n","def computeIOU(output, target):\n","  output = torch.argmax(output, dim=1).flatten() \n","  target = target.flatten()\n","  \n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  intersection = torch.sum(output * target)\n","  union = torch.sum(target) + torch.sum(output) - intersection\n","  iou = (intersection + .0000001) / (union + .0000001)\n","  \n","  if iou != iou:\n","    print(\"failed, replacing with 0\")\n","    iou = torch.tensor(0).float()\n","  \n","  return iou\n","  \n","def computeAccuracy(output, target):\n","  output = torch.argmax(output, dim=1).flatten() \n","  target = target.flatten()\n","  \n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  correct = torch.sum(output.eq(target))\n","  \n","  return correct.float() / len(target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akehPRCh-ZMn"},"outputs":[],"source":["def getArrFlood(fname):\n","    return rasterio.open(fname).read()\n","\n","def download_flood_test_data_from_list(l):\n","  \n","  i = 0\n","  tot_nan = 0\n","  tot_good = 0\n","  flood_data = []\n","  for (s2_fname,mask_fname) in l:\n","\n","    if not os.path.exists(s2_fname):\n","      print(\"(((((\")\n","      continue\n","\n","    # arr_vv = np.nan_to_num(getArrFlood(vv_fname))\n","    # arr_vh=np.nan_to_num(getArrFlood(vh_fname))\n","    # arr_s1 = np.zeros((2,512,512), dtype=float)\n","    # arr_s1[0,:,:]=arr_vv\n","    # arr_s1[1,:,:]=arr_vh\n","    #print(arr_s1.shape)\n","\n","    arr_s2 = np.nan_to_num(getArrFlood(s2_fname))[1:,:,:]\n","    \n","    arr_y = getArrFlood(mask_fname)\n","    arr_y[arr_y == -1] = 255\n","\n","    # arr_s1 = np.clip(arr_s1, -50, 1)\n","    # arr_s1 = (arr_s1 + 50) / 51\n","\n","    if i % 100 == 0:\n","      # print(vv_fname,vh_fname, mask_fname)\n","      print(s2_fname, mask_fname)\n","    i += 1\n","    flood_data.append((arr_s2,arr_y))\n","\n","  return flood_data\n"," \n","\n","def load_flood_test_data(path):\n","  input_root_s2 =path+'S2/'\n","  label_root=path+'Labels/'\n","  fname = path+\"flood_test_data.csv\"\n","  training_files = []\n","  with open(fname) as f:\n","    for line in csv.reader(f):\n","      training_files.append(tuple((input_root_s2+line[2], label_root+line[3])))\n","      \n","  print(training_files)\n","\n","  return download_flood_test_data_from_list(training_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxngG9ihTfA0"},"outputs":[],"source":["test_data = load_flood_test_data(test_path)\n","print(len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gXInZrWTi7h"},"outputs":[],"source":["def test_loop(test_data, net):\n","    net = net.eval()\n","    net = net.cuda()\n","    count = 0\n","    iou = 0\n","    loss = 0\n","    accuracy = 0\n","    \n","    with torch.no_grad():\n","        print(len(test_data))\n","        for i in range(0,len(test_data)):\n","            (images,labels)=processTestIm(test_data[i])\n","        \n","            net = net.cuda()\n","            \n","            print(i)\n","            outputs = net(images.cuda())\n","            valid_loss = criterion(outputs, labels.long().cuda())\n","            valid_iou = computeIOU(outputs, labels.cuda())\n","            iou += valid_iou\n","            accuracy += computeAccuracy(outputs, labels.cuda())\n","            count += 1\n","\n","            output = torch.argmax(outputs, dim=1).flatten() \n","\n","            output=output.cpu().numpy()\n","\n","            output=np.array(output)\n","            output=output.reshape((4,256,256))\n","            image=images.reshape((4,5,256,256))\n","\n","            label = labels.cuda().flatten()\n","            #print(label.shape)\n","            label=label.cpu().numpy()\n","            #print(label.shape)\n","            label=np.array(label)\n","            label=label.reshape((4,256,256))\n","\n","            for i in range(0,4):\n","\n","                # x1 = np.roll(output[i].cpu(),-1,0)\n","                #print(output[i].shape)\n","\n","\n","                _, ax = plt.subplots(1, 5,)\n","                ax[0].imshow(output[i])\n","                ax[0].set_title('pred')\n","\n","                ax[1].imshow(label[i])\n","                ax[1].set_title('label')\n","                \n","                ax[2].imshow(image[i][2])\n","                ax[2].set_title('s2')\n","\n","                ax[3].imshow(image[i][3])\n","                ax[3].set_title('s2')\n","\n","                ax[4].imshow(image[i][4])\n","                ax[4].set_title('s2')\n","\n","\n","\n","                plt.show()\n","\n","    iou = iou / count\n","    print(\"Test IOU:\", iou)\n","    print(\"Test Accuracy:\", accuracy / count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIxA7VS37B_Y"},"outputs":[],"source":["model_name = 'Perus_part_s2_3_4_0.5840604901313782.cp'\n","\n","model_path = model_save_path + model_name\n","model=torch.load(model_path)\n","test_loop(test_data, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfGaXKTHCP-8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FQYdzwgL6eKx"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMjzKS5tDNnvQGllUNYKCLE","collapsed_sections":[],"name":"BAN.ipynb（副本）","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('pytorch')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.7"},"vscode":{"interpreter":{"hash":"b7c271530999d054573ad5abc9a81bc81b393c5c05b17516ef68f547b41d67ca"}}},"nbformat":4,"nbformat_minor":0}
